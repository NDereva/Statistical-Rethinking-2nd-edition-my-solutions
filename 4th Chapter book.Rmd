---
title: "4 chapter book"
author: "Mykola Dereva"
date: "1/19/2021"
output: html_document
---

```{r message=FALSE, warning=FALSE}
rm(list = ls())
library(rethinking)
library(dplyr)

```


```{r}
growth <- replicate(1e4, prod(1 + runif(12,0,0.1)))
dens(growth, norm.comp = TRUE)
```


```{r}
big <- replicate(1e4, prod(1 + runif(12,0,0.5)))
small <- replicate(1e4, prod(1 + runif(12,0,0.01)))

dens(big, norm.comp = TRUE)
dens(small, norm.comp = TRUE)
```


```{r}
log.big <- replicate(1e4, log(prod(1 + runif(12,0,0.5))))
dens(log.big, norm.comp = TRUE)
```



# Gausian model of height

```{r}
data(Howell1)
d <- Howell1
str(d)
```

```{r}
precis(d, hist = FALSE)
```

```{r}
d2 <- d %>% 
  filter(age >= 18)
```


```{r}
curve(dnorm(x , 178 , 20) , from = 100 , to = 250)
```
```{r}
curve(dunif(x , 0 , 50) , from = -10 , to = 60)
```

prior predictive distribution

```{r}
sample_mu <- rnorm(1e4, 178, 20)
sample_sigma <- runif(1e4, 0, 15)

prior_h <- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_h)
```



# Grid approximaiton

```{r}
#  establish the range of µ and σ values, respectively, to calculate over
mu.list <- seq(from = 150, to = 160, length.out = 100)
sigma.list <- seq(from = 7, to = 9, length.out = 100)

#expands chosen µ and σ values into a matrix of all of the combinations of µ and σ
post <- expand.grid(mu = mu.list, sigma = sigma.list)

# pass the unique combination of µ and σ on each row of
# post to a function that computes the log-likelihood of each observed height,
# and adds all of these log-likelihoods

post$LL <- sapply(1:nrow(post), function(i) sum(
  dnorm(d2$height , post$mu[i] , post$sigma[i] , log = TRUE )))


# multiply the prior by the likelihood to get the product that is proportional
# to the posterior density.
# priors are also on the log scale, and so we add them to the log-likelihood, which is
# equivalent to multiplying the raw densities by the likelihood
post$prod <- post$LL + dnorm(post$mu, 178, 20, log = TRUE) +
  dunif(post$sigma, 0, 50, log = TRUE)

#relative posterior probabilities
post$relative_LL <- post$prod - max(post$prod)
post$prob <- exp(post$relative_LL)
```

```{r}
contour_xyz(post$mu, post$sigma, post$prob)
```

```{r}
image_xyz(post$mu, post$sigma, post$prob)
```

mu and sigma with the max probability
```{r}
post[which.max(post$prob), c("mu", "sigma", "prob")]
```

Sampling from the posterior

```{r}
sample.rows <- sample(1:nrow(post), size = 1e4, replace = TRUE, prob = post$prob)
sample.mu <- post$mu[sample.rows]
sample.sigma <- post$sigma[sample.rows]
```

```{r}
plot(sample.mu, sample.sigma, cex = 2, pch = 16, col = col.alpha(rangi2, 0.05))

```

```{r}
dens( sample.mu )
```

```{r}
dens( sample.sigma )
```

```{r}
PI( sample.mu )

```

```{r}
PI( sample.sigma )
```


# Quadratic approximation

```{r}
flist <- alist(
  height ~ dnorm(mu, sigma),
  mu ~ dnorm(178, 20),
  sigma ~ dunif(0, 50)
  )

start <- list(
  mu = mean(d2$height),
  sigma = sd(d2$height)
  )
```

```{r}
m4.1 <- quap(flist, start = start, data = d2)
```


```{r}
precis(m4.1)
```
The parameters are the same as in the grid aproximation


Variance of the each parameter
```{r}
diag(vcov( m4.1 ))
```
Correlation between paremeters 
```{r}
cov2cor(vcov(m4.1))
```



# Sampling from a quap

```{r}
post <- extract.samples(m4.1, n = 1e4)
```
```{r}
head(post)
```

```{r}
dens(post$mu)
```

```{r}
dens(post$sigma)
```


#  Linear prediction

```{r}
plot(d2$height ~ d2$weight)
```

```{r}
xbar <- mean(d2$weight)
```

```{r}
specs <- alist(
  height ~ dnorm(mu, sigma),
  mu <- a + b * (weight - xbar),
  a ~ dnorm(178, 20),
  b ~ dlnorm(0, 1),
  sigma ~ dunif(0, 50)
)

m4.2 <- quap(specs, data = d2)
```

```{r}
precis(m4.2)
```


```{r}
pairs(m4.2)
```



```{r}
plot(height ~ weight , data = d2 , col = rangi2)
post <- extract.samples(m4.2)
a_map <- mean(post$a)
b_map <- mean(post$b)
curve(a_map + b_map*(x - xbar), add = TRUE)
```



```{r}
N <- 150

dN <- d2[1:N ,]
mN <- quap(
alist(
  height ~ dnorm( mu , sigma ) ,
  mu <- a + b*(weight - mean(weight)),
  a ~ dnorm( 178 , 20 ) ,
  b ~ dlnorm( 0 , 1 ) ,
  sigma ~ dunif( 0 , 50 )
  ) , data = dN 
)

# extract 20 samples from the posterior
post <- extract.samples( mN , n = 20 )

# display raw data and sample size
plot( dN$weight , dN$height ,
  xlim = range(d2$weight) , ylim = range(d2$height) ,
  col = rangi2 , xlab = "weight" , ylab = "height" )
mtext(concat("N = ",N))

# plot the lines, with transparency
for (i in 1:20) {
  curve( post$a[i] + post$b[i]*(x - mean(dN$weight)) ,
  col = col.alpha("black", 0.3) , add = TRUE )
}

```

```{r}
post <- extract.samples( m4.2 )
mu_at_60 <- post$a + post$b * (60 - xbar)

dens( mu_at_60 , col = rangi2 , lwd = 2 , xlab = "mu|weight=60")
```


```{r}
# define sequence of weights to compute predictions for 4.54
# these values will be on the horizontal axis
weight.seq <- seq(from = 25 , to = 70 , by = 1)
# use link to compute mu
# for each sample from posterior
# and for each weight in weight.seq
mu <- link(m4.2 , data = data.frame(weight = weight.seq))
str(mu)
```

```{r}
# use type="n" to hide raw data 4.55
plot(height ~ weight, d2 , type = "n")
# loop over samples and plot each mu value

for (i in 1:100 ) {
  points(weight.seq, mu[i,] , pch = 16 , col = col.alpha(rangi2,0.1))
}

```



```{r}
# summarize the distribution of mu
mu.mean <- apply(mu, 2, mean)
mu.PI <- apply(mu, 2, PI, prob = 0.89)
```


```{r}
# plot raw data
# fading out points to make line and interval more visible
plot(height ~ weight, data = d2 , col = col.alpha(rangi2,0.5))

# plot the MAP line, aka the mean mu for each weight
lines(weight.seq, mu.mean)

# plot a shaded region for 89% PI
shade(mu.PI, weight.seq)
```

Prediction interval 

```{r}
sim.height <- sim(m4.2, data = list(weight = weight.seq), n = 1e4)
str(sim.height)
```

```{r}
height.PI <- apply(sim.height, 2, PI, prob = 0.89)

# plot raw data
plot(height ~ weight, d2, col = col.alpha(rangi2,0.5))

# draw MAP line
lines(weight.seq, mu.mean)

# draw HPDI region for line
shade(mu.PI, weight.seq)

# draw PI region for simulated heights
shade(height.PI, weight.seq)
```



# Polinomial regression

```{r}
d <- d %>% 
  mutate(weight_s = (weight - mean(weight)) / sd(weight),
         weight_s2 = weight_s ^ 2)

m4.4 <- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu <- a + b1*weight_s + b2*weight_s2,
    a ~ dnorm(178, 20),
    b1 ~ dlnorm(0, 1),
    b2 ~ dnorm(0, 2),
    sigma ~ dunif(0, 50)
  ), data = d
)
```

```{r}
precis(m4.4)
```



```{r}
weight.seq <- seq(from = min(d$weight_s), to = max(d$weight_s), length.out = 30)
pred_dat <- list(weight_s = weight.seq, weight_s2 = weight.seq^2)
mu <- link(m4.4, data = pred_dat)
mu.mean <- apply(mu, 2, mean)
mu.PI <- apply(mu, 2, PI, prob = 0.89)
sim.height <- sim(m4.4, data = pred_dat, n = 5e3)
height.PI <- apply(sim.height, 2, PI, prob = 0.89)
```

```{r}
plot(height ~ weight_s, d, col = col.alpha(rangi2,0.5))
lines(weight.seq, mu.mean)
shade(mu.PI, weight.seq)
shade(height.PI, weight.seq)
```


Parabolic model
```{r}
d$weight_s3 <- d$weight_s^3
m4.6 <- quap(
  alist(
    height ~ dnorm( mu , sigma ) ,
    mu <- a + b1*weight_s + b2*weight_s2 + b3*weight_s3 ,
    a ~ dnorm( 178 , 20 ) ,
    b1 ~ dlnorm( 0 , 1 ) ,
    b2 ~ dnorm( 0 , 10 ) ,
    b3 ~ dnorm( 0 , 10 ) ,
    sigma ~ dunif( 0 , 50 )
  ) , data = d)
```

```{r}
precis(m4.6)
```

```{r}
weight.seq <- seq(from = min(d$weight_s), to = max(d$weight_s), length.out = 30)
pred_dat <- list(weight_s = weight.seq, weight_s2 = weight.seq^2, weight_s3 = weight.seq^3)
mu <- link(m4.6, data = pred_dat)
mu.mean <- apply(mu, 2, mean)
mu.PI <- apply(mu, 2, PI, prob = 0.89)
sim.height <- sim(m4.6, data = pred_dat, n = 5e3)
height.PI <- apply(sim.height, 2, PI, prob = 0.89)

plot(height ~ weight_s, d, col = col.alpha(rangi2,0.5))
lines(weight.seq, mu.mean)
shade(mu.PI, weight.seq)
shade(height.PI, weight.seq)
```



# Splines


```{r}
data(cherry_blossoms)
d <- cherry_blossoms
precis(d, hist = F)
```


```{r}
d2 <- d[ complete.cases(d$doy) , ] # complete cases on doy
num_knots <- 20
knot_list <- quantile( d2$year , probs = seq(0, 1, length.out = num_knots) )
```


```{r}
library(splines)

B <- bs(d2$year,
  knots = knot_list[-c(1,num_knots)],
  degree = 3, intercept = TRUE)
```



```{r}
plot(NULL, xlim = range(d2$year), ylim = c(0,1), xlab = "year", ylab = "basis")
for (i in 1:ncol(B) ) lines( d2$year , B[,i] )
```



```{r}
m4.7 <- quap(
  alist(
    D ~ dnorm(mu, sigma) ,
    mu <- a + B %*% w ,
    a ~ dnorm(100, 10),
    w ~ dnorm(0, 10),
    sigma ~ dexp(1)
  ), data = list(D = d2$doy, B = B) ,
  start = list(w = rep(0, ncol(B) ))
)
```

```{r}
precis(m4.7, depth = 2)
```



```{r}
post <- extract.samples(m4.7)
w <- apply(post$w , 2 , mean)
plot(NULL , xlim = range(d2$year) , ylim = c(-6,6) ,
xlab = "year" , ylab = "basis * weight" )
for (i in 1:ncol(B)) lines(d2$year , w[i]*B[,i] )
```


```{r}
mu <- link(m4.7)
mu_PI <- apply(mu, 2, PI, 0.97)
plot(d2$year, d2$doy, col = col.alpha(rangi2,0.3) , pch = 16)
shade(mu_PI, d2$year, col = col.alpha("black", 0.3))
```

